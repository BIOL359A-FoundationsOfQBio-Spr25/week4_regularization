{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Biol 359A | Regularization\n",
    "### Spring 2025, Week 4\n",
    "Objectives:\n",
    "- Understand the Bias-Variance Tradeoff: Learn how increasing model complexity impacts bias and variance.\n",
    "- Gain intuition for Regularization Techniques: Implement Ridge and LASSO to prevent overfitting.\n",
    "- Implement Model Evaluation and Selection: Employ train-test splits for optimal model selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from ipywidgets import interact, interactive, widgets\n",
    "import seaborn as sns\n",
    "import textwrap\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Today we will start by working with in-silico data. The code below will generate the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! rm -r week4_regularization/\n",
    "! git clone https://github.com/BIOL359A-FoundationsOfQBio-Spr25/week4_regularization.git\n",
    "! cp -r week4_regularization/* .\n",
    "! ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/synthetic_data.csv\")\n",
    "print(df.head())\n",
    "sns.scatterplot(df, x=\"x\", y=\"y\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to build a linear regression model that will help us learn about the system that generated these data. Please choose various coefficients for different complexity of the models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df['x'].values\n",
    "y = df['y'].values\n",
    "\n",
    "# Function to compute model prediction for different polynomial orders\n",
    "def compute_polynomial(x, coeffs):\n",
    "    \"\"\"Compute polynomial of specified order with given coefficients\"\"\"\n",
    "    result = 0\n",
    "    for i, coeff in enumerate(coeffs):\n",
    "        result += coeff * (x ** i)\n",
    "    return result\n",
    "\n",
    "# Function to compute error (Mean Squared Error)\n",
    "def compute_mse(y_true, y_pred):\n",
    "    \"\"\"Compute Mean Squared Error\"\"\"\n",
    "    return np.mean((y_true - y_pred) ** 2)\n",
    "\n",
    "# Order 1 model: y = beta_0 + beta_1*x\n",
    "@interact(\n",
    "    beta_0=widgets.FloatSlider(min=-30, max=30, step=0.1, value=0, description='β₀:'),\n",
    "    beta_1=widgets.FloatSlider(min=-15, max=15, step=0.1, value=0, description='β₁:')\n",
    ")\n",
    "def order1_model(beta_0, beta_1):\n",
    "    # Compute the model prediction\n",
    "    coeffs = [beta_0, beta_1]\n",
    "    y_pred = compute_polynomial(x, coeffs)\n",
    "    \n",
    "    # Compute error\n",
    "    mse = compute_mse(y, y_pred)\n",
    "    \n",
    "    # Sort for plotting smooth curve\n",
    "    sort_idx = np.argsort(x)\n",
    "    x_sorted = x[sort_idx]\n",
    "    y_pred_sorted = y_pred[sort_idx]\n",
    "    \n",
    "    # Plot\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.scatter(x, y, color='blue', alpha=0.6, label='Data')\n",
    "    plt.plot(x_sorted, y_pred_sorted, color='red', linewidth=2, \n",
    "             label=f'y = {beta_0:.1f} + {beta_1:.1f}x')\n",
    "    plt.xlabel('x')\n",
    "    plt.ylabel('y')\n",
    "    plt.title(f'First-Order Model (MSE: {mse:.2f})')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"Mean Squared Error: {mse:.4f}\")\n",
    "    #return mse\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Second order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Order 2 model: y = beta_0 + beta_1*x + beta_2*x^2\n",
    "@interact(\n",
    "    beta_0=widgets.FloatSlider(min=-30, max=30, step=0.1, value=0, description='β₀:'),\n",
    "    beta_1=widgets.FloatSlider(min=-15, max=15, step=0.1, value=0, description='β₁:'),\n",
    "    beta_2=widgets.FloatSlider(min=-5, max=5, step=0.05, value=0, description='β₂:')\n",
    ")\n",
    "def order2_model(beta_0, beta_1, beta_2):\n",
    "    # Compute the model prediction\n",
    "    coeffs = [beta_0, beta_1, beta_2]\n",
    "    y_pred = compute_polynomial(x, coeffs)\n",
    "    \n",
    "    # Compute error\n",
    "    mse = compute_mse(y, y_pred)\n",
    "    \n",
    "    # Sort for plotting smooth curve\n",
    "    sort_idx = np.argsort(x)\n",
    "    x_sorted = x[sort_idx]\n",
    "    y_pred_sorted = y_pred[sort_idx]\n",
    "    \n",
    "    # Plot\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.scatter(x, y, color='blue', alpha=0.6, label='Data')\n",
    "    plt.plot(x_sorted, y_pred_sorted, color='red', linewidth=2, \n",
    "             label=f'y = {beta_0:.1f} + {beta_1:.1f}x + {beta_2:.2f}x²')\n",
    "    plt.xlabel('x')\n",
    "    plt.ylabel('y')\n",
    "    plt.title(f'Second-Order Model (MSE: {mse:.2f})')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"Mean Squared Error: {mse:.4f}\")\n",
    "    #return mse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Third order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Order 3 model: y = beta_0 + beta_1*x + beta_2*x^2 + beta_3*x^3\n",
    "@interact(\n",
    "    beta_0=widgets.FloatSlider(min=-30, max=30, step=0.1, value=0, description='β₀:'),\n",
    "    beta_1=widgets.FloatSlider(min=-15, max=15, step=0.1, value=0, description='β₁:'),\n",
    "    beta_2=widgets.FloatSlider(min=-5, max=5, step=0.05, value=0, description='β₂:'),\n",
    "    beta_3=widgets.FloatSlider(min=-1, max=1, step=0.01, value=0, description='β₃:')\n",
    ")\n",
    "def order3_model(beta_0, beta_1, beta_2, beta_3):\n",
    "    # Compute the model prediction\n",
    "    coeffs = [beta_0, beta_1, beta_2, beta_3]\n",
    "    y_pred = compute_polynomial(x, coeffs)\n",
    "    \n",
    "    # Compute error\n",
    "    mse = compute_mse(y, y_pred)\n",
    "    \n",
    "    # Sort for plotting smooth curve\n",
    "    sort_idx = np.argsort(x)\n",
    "    x_sorted = x[sort_idx]\n",
    "    y_pred_sorted = y_pred[sort_idx]\n",
    "    \n",
    "    # Plot\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.scatter(x, y, color='blue', alpha=0.6, label='Data')\n",
    "    plt.plot(x_sorted, y_pred_sorted, color='red', linewidth=2, \n",
    "             label=f'y = {beta_0:.1f} + {beta_1:.1f}x + {beta_2:.2f}x² + {beta_3:.2f}x³')\n",
    "    plt.xlabel('x')\n",
    "    plt.ylabel('y')\n",
    "    plt.title(f'Third-Order Model (MSE: {mse:.2f})')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"Mean Squared Error: {mse:.4f}\")\n",
    "    #return mse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Co-linearity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Number of samples\n",
    "n_samples = 200\n",
    "\n",
    "# Generate data where x1 and x2 are perfectly correlated (same pathway)\n",
    "# but neither is related to the disease\n",
    "x3 = np.random.normal(0, 1, n_samples)  # The true driver\n",
    "\n",
    "# Generate x1 (and therefore x2 since they're in perfect correlation)\n",
    "x1 = np.random.normal(0, 1, n_samples)\n",
    "x2 = x1 + np.random.normal(0, 0.01, n_samples)  # Adding tiny noise to avoid perfect multicollinearity\n",
    "\n",
    "# Generate disease state based only on x3\n",
    "y = 5 * x3 + np.random.normal(0, 1, n_samples)  # Adding some noise to the disease state\n",
    "\n",
    "# Create a dataframe for visualization\n",
    "df = pd.DataFrame({\n",
    "    'x1': x1,\n",
    "    'x2': x2,\n",
    "    'x3': x3,\n",
    "    'disease_state': y\n",
    "})\n",
    "\n",
    "# Visualize the relationships\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "# Relationship between x1 and x2 (same pathway)\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.scatter(df['x1'], df['x2'], alpha=0.6)\n",
    "plt.title('x1 vs x2 (Same Pathway)')\n",
    "plt.xlabel('x1 Expression')\n",
    "plt.ylabel('x2 Expression')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Relationship between x1 and disease\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.scatter(df['x1'], df['disease_state'], alpha=0.6)\n",
    "plt.title('x1 vs Disease State')\n",
    "plt.xlabel('x1 Expression')\n",
    "plt.ylabel('Disease State')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Relationship between x2 and disease\n",
    "plt.subplot(2, 2, 3)\n",
    "plt.scatter(df['x2'], df['disease_state'], alpha=0.6)\n",
    "plt.title('x2 vs Disease State')\n",
    "plt.xlabel('x2 Expression')\n",
    "plt.ylabel('Disease State')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Relationship between x3 and disease\n",
    "plt.subplot(2, 2, 4)\n",
    "plt.scatter(df['x3'], df['disease_state'], alpha=0.6)\n",
    "plt.title('x3 vs Disease State (True Driver)')\n",
    "plt.xlabel('x3 Expression')\n",
    "plt.ylabel('Disease State')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Now let's fit the model\n",
    "X = df[['x1', 'x2', 'x3']].values\n",
    "y = df['disease_state'].values\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X, y)\n",
    "\n",
    "# Get the coefficients\n",
    "coefficients = model.coef_\n",
    "\n",
    "print(\"Model Coefficients:\")\n",
    "print(f\"β1 (x1): {coefficients[0]:.4f}\")\n",
    "print(f\"β2 (x2): {coefficients[1]:.4f}\")\n",
    "print(f\"β3 (x3): {coefficients[2]:.4f}\")\n",
    "print(\"\\nTrue relationships:\")\n",
    "print(\"- x1 and x2 are in the same pathway\")\n",
    "print(\"- x1 and x2 have no effect on disease\")\n",
    "print(\"- x3 is the true driver with effect = 5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run multiple simulations to see the distribution of β1 and β2\n",
    "n_simulations = 500\n",
    "beta1_values = []\n",
    "beta2_values = []\n",
    "beta3_values = []\n",
    "\n",
    "for i in range(n_simulations):\n",
    "    # Generate new random data for each simulation\n",
    "    np.random.seed(i)\n",
    "    \n",
    "    # Generate true driver\n",
    "    x3 = np.random.normal(0, 1, n_samples)\n",
    "    \n",
    "    # Generate x1 and x2 (same pathway but unrelated to disease)\n",
    "    x1 = np.random.normal(0, 1, n_samples)\n",
    "    x2 = x1 + np.random.normal(0, 0.01, n_samples)\n",
    "    \n",
    "    # Generate disease state based only on x3\n",
    "    y = 5 * x3 + np.random.normal(0, 1, n_samples)\n",
    "    \n",
    "    # Fit model\n",
    "    X = np.column_stack([x1, x2, x3])\n",
    "    model = LinearRegression()\n",
    "    model.fit(X, y)\n",
    "    \n",
    "    # Store coefficients\n",
    "    beta1_values.append(model.coef_[0])\n",
    "    beta2_values.append(model.coef_[1])\n",
    "    beta3_values.append(model.coef_[2])\n",
    "\n",
    "# Create a dataframe of coefficient values\n",
    "coef_df = pd.DataFrame({\n",
    "    'β1': beta1_values,\n",
    "    'β2': beta2_values,\n",
    "    'β3': beta3_values\n",
    "})\n",
    "\n",
    "# Plot the distribution of β1 and β2\n",
    "plt.figure(figsize=(7, 3))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.histplot(coef_df['β1'], kde=True)\n",
    "plt.axvline(x=0, color='red', linestyle='--')\n",
    "plt.title('Distribution of β1 Estimates')\n",
    "plt.xlabel('β1 Value')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.histplot(coef_df['β2'], kde=True)\n",
    "plt.axvline(x=0, color='red', linestyle='--')\n",
    "plt.title('Distribution of β2 Estimates')\n",
    "plt.xlabel('β2 Value')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Plot the relationship between β1 and β2\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.scatter(coef_df['β1'], coef_df['β2'], alpha=0.5)\n",
    "plt.axhline(y=0, color='red', linestyle='--', alpha=0.5)\n",
    "plt.axvline(x=0, color='red', linestyle='--', alpha=0.5)\n",
    "plt.title('Relationship Between β1 and β2 Estimates')\n",
    "plt.xlabel('β1 Value')\n",
    "plt.ylabel('β2 Value')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Add correlation value\n",
    "corr = coef_df['β1'].corr(coef_df['β2'])\n",
    "plt.annotate(f'Correlation: {corr:.4f}', \n",
    "             xy=(0.05, 0.95), \n",
    "             xycoords='axes fraction',\n",
    "             bbox=dict(boxstyle=\"round,pad=0.3\", fc=\"white\", alpha=0.8))\n",
    "\n",
    "# Calculate the sum of β1 and β2 for each simulation\n",
    "coef_df['β1 + β2'] = coef_df['β1'] + coef_df['β2']\n",
    "\n",
    "# Plot the distribution of β1 + β2\n",
    "plt.figure(figsize=(4, 3))\n",
    "sns.histplot(coef_df['β1 + β2'], kde=True)\n",
    "plt.axvline(x=0, color='red', linestyle='--')\n",
    "plt.title('Distribution of β1 + β2 (Sum of Coefficients)')\n",
    "plt.xlabel('β1 + β2 Value')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "# Create a summary of the findings\n",
    "print(\"\\n----- ANALYSIS OF POSSIBLE VALUES FOR β1 AND β2 -----\")\n",
    "print(f\"Mean β1: {coef_df['β1'].mean():.4f}\")\n",
    "print(f\"Mean β2: {coef_df['β2'].mean():.4f}\")\n",
    "print(f\"Mean β3: {coef_df['β3'].mean():.4f}\")\n",
    "print(f\"Standard deviation of β1: {coef_df['β1'].std():.4f}\")\n",
    "print(f\"Standard deviation of β2: {coef_df['β2'].std():.4f}\")\n",
    "print(f\"Correlation between β1 and β2: {corr:.4f}\")\n",
    "print(f\"Mean of β1 + β2: {coef_df['β1 + β2'].mean():.4f}\")\n",
    "print(f\"Standard deviation of β1 + β2: {coef_df['β1 + β2'].std():.4f}\")\n",
    "\n",
    "print(\"\\nPossible values of β1 and β2:\")\n",
    "print(\"1. The true values of both β1 and β2 are 0 (since they don't affect the disease).\")\n",
    "print(\"2. However, due to collinearity, the estimates can take many values.\")\n",
    "print(\"3. The estimates of β1 and β2 are highly negatively correlated.\")\n",
    "print(\"4. β1 and β2 act like a seesaw: when one goes up, the other goes down.\")\n",
    "print(\"5. The sum β1 + β2 tends to be close to zero (the true combined effect).\")\n",
    "print(\"6. Any combination where β1 ≈ -β2 is a possible outcome.\")\n",
    "print(\"7. The model cannot distinguish between the effects of x1 and x2.\")\n",
    "print(\"8. In some simulations, both β1 and β2 can appear statistically significant despite having no true effect.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
